{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMARI HAMZA & hamzaoui thameur G2 \n",
    "## Projet : Fruits detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import os, shutil, pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup directories and cleaning data of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the directory of training, test and validation data\n",
    "data_dir_train = \"C:/Users/msihamza/Desktop/projet/Data/train\"\n",
    "data_dir_validation = \"C:/Users/msihamza/Desktop/projet/Data/valid\"\n",
    "data_dir_test = \"C:/Users/msihamza/Desktop/projet/Data/test\"\n",
    "\n",
    "# Managing the extension of the files\n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify image dimensions\n",
    "IMAGE_SHAPE = (150, 150)\n",
    "\n",
    "# Load data\n",
    "# Load data with data augmentation\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    shear_range=.2,\n",
    "    zoom_range=.2,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir_train,\n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    data_dir_validation,\n",
    "    shuffle=False,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir_test,\n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Check names and number of classes\n",
    "names_of_classes = sorted(os.listdir(data_dir_test))\n",
    "print(f\"\\nNames of Classes : {names_of_classes}\".format(names_of_classes))\n",
    "number_of_classes = len(names_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of images in each subfolder for each class\n",
    "\n",
    "def count_files_in_subfolder(subfolder):\n",
    "    \n",
    "    for path in pathlib.Path(subfolder).iterdir():\n",
    "        if path.is_dir():\n",
    "            print(\"Class \" + str(path.name) + \": \" + \\\n",
    "                  str(len([name for name in os.listdir(path) \\\n",
    "            if os.path.isfile(os.path.join(path, name))])) + \" files\")\n",
    "\n",
    "print(\"Train data:\")\n",
    "count_files_in_subfolder(os.path.join(data_dir_train))\n",
    "print(\"\\nTest data:\")\n",
    "count_files_in_subfolder(os.path.join(data_dir_test))\n",
    "print(\"\\nValidation data:\")\n",
    "count_files_in_subfolder(os.path.join(data_dir_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model object\n",
    "model = Sequential()\n",
    "\n",
    "# Add Layers\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Flatten the feature map\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layers\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5) # Set up callbacks\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator, \n",
    "    epochs=10, \n",
    "    verbose=1, \n",
    "    validation_data=valid_generator, \n",
    "    steps_per_epoch = 320//32, \n",
    "    validation_steps = 40//32, \n",
    "    callbacks=early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plotting the error and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "evaluation = model.evaluate(valid_generator)\n",
    "print(\"Validation Loss: {:.2f}\".format(evaluation[0]))\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
    "\n",
    "# Test the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss: {:.2f}\".format(test_loss))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the \n",
    "test_image_path = r'C:\\Users\\msihamza\\Desktop\\projet\\Data\\train\\betterave\\IMG_20230529_192446.jpg'\n",
    "\n",
    "def generate_predictions(test_image_path, actual_label):\n",
    "    \n",
    "    # 1. Load and preprocess the image\n",
    "    test_img = image.load_img(test_image_path, target_size=(150, 150))\n",
    "    test_img_arr = image.img_to_array(test_img)/255.0\n",
    "    test_img_input = test_img_arr.reshape((1, test_img_arr.shape[0], test_img_arr.shape[1], test_img_arr.shape[2]))\n",
    "\n",
    "    # 2. Make Predictions\n",
    "    predicted_label = np.argmax(model.predict(test_img_input))\n",
    "    predicted_vegetable = names_of_classes[predicted_label]\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(test_img_arr)\n",
    "    plt.title(\"Predicted Label: {}, Actual Label: {}\".format(predicted_vegetable, actual_label))\n",
    "    plt.grid()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# call the function\n",
    "generate_predictions(test_image_path, actual_label='betterave')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Veg1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], label='Training Loss')\n",
    "plt.plot(hist.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_generator:\n",
    "    predictions = model.predict(images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    misclassified_indices = np.where(predicted_labels != np.argmax(labels, axis=1))[0]\n",
    "    \n",
    "    for index in misclassified_indices:\n",
    "        img = images[index]\n",
    "        true_label = np.argmax(labels[index])\n",
    "        predicted_label = predicted_labels[index]\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    break  # Show only the first batch of misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model('C:/Users/msihamza/Desktop/projet/Veg1.h5')\n",
    "\n",
    "# Load an image for prediction\n",
    "image_path = 'C:/Users/msihamza/Desktop/projet/Data/test/oignon/IMG_20230529_191928.jpg'\n",
    "img = image.load_img(image_path, target_size=IMAGE_SHAPE)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict(img_array)\n",
    "predicted_label = np.argmax(predictions[0])\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"Predicted Label: {names_of_classes[predicted_label]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
